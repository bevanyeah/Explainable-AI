{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub: https://github.com/bevanyeah/assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Welcome to your assignment this week! \n",
    "\n",
    "To better understand the adverse use of AI, in this assignment, we will look at a Natural Language Processing use case.\n",
    "\n",
    "\n",
    "Natural Language Pocessing (NLP) is a branch of Artificial Intelligence (AI) that helps computers to understand, to interpret and to manipulate natural (i.e. human) language.\n",
    "Imagine NLP-powered machines as black boxes that are capable of understanding and evaluating the context of the input documents (i.e. collection of words), outputting meaningful results that depend on the task the machine is designed for.\n",
    "\n",
    "\n",
    "![](imgs/1_3zMvUnPzYZF9CSHdj6hT5A.png)\n",
    "\n",
    "<caption><center> Documents are fed into magic NLP model capable to get, for instance, the sentiment of the original content</center></caption>\n",
    "\n",
    "\n",
    "In this notebook, you will implement a model that uses an LSTM to generate fake tweets and comments. You will also be able to try it to generate your own fake text. \n",
    "\n",
    "**You will learn to:**\n",
    "- Apply an LSTM to generate fake comments.\n",
    "- Generate your own fake text with deep learning.\n",
    "\n",
    "Please run the following cell to load all the packages required in this assignment. This may take a few minutes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install keras\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.utils as ku \n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a tokenizer and read the data from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "data = open('covid19_fake.txt').read().replace(\".\", \" . \").replace(\",\", \" , \").replace(\"?\", \" ? \").replace(\"!\", \" ! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's splits the data into tweets  where each line of the input file is a fake tweets.\n",
    "\n",
    "We also extract the vocabulary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.lower().split(\"\\n\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- `corpus`: an array where each entry is a fake post.\n",
    "- `tokenizer`: which is the object that we will use to vectorize our dataset. This object also contains our word index.\n",
    "- `total_words`: is the total number of words in the vacabulary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of fake tweets:  ['there is already a vaccine to treat covid19 . ', 'cleaning hands do not help to prevent covid19 . ']\n",
      "Size of the vocabulary =  1257\n",
      "Example of our word index =  [('.', 1), ('the', 2), ('covid19', 3), ('in', 4), ('to', 5), ('a', 6), ('of', 7), (',', 8), ('coronavirus', 9), ('and', 10)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Example of fake tweets: \",corpus[:2])\n",
    "print(\"Size of the vocabulary = \", total_words)\n",
    "index = [(k, v) for k, v in tokenizer.word_index.items()]\n",
    "print(\"Example of our word index = \", index[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step aims to generate the training set of n_grams sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've create:\n",
    "- `input_sequences`: which is a list of n_grams sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entry  20  in 'input_sequences' is: \n",
      "[2, 3, 12, 187, 34, 188]\n",
      " and it corresponds to:\n",
      "the covid19 is same as sars "
     ]
    }
   ],
   "source": [
    "sample = 20\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences[sample])\n",
    "print(\" and it corresponds to:\")\n",
    "for i in input_sequences[sample]:\n",
    "    print(reverse_word_map[i], end=' ')\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we padd our training set to the max length in order to be able to make a batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following to see the containt of the padded 'input_sequences' object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entry  20  in 'input_sequences' is: \n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   3  12 187  34 188]\n",
      " and it corresponds to:\n",
      "[ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ __ the covid19 is same as sars ]\n"
     ]
    }
   ],
   "source": [
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences[sample])\n",
    "print(\" and it corresponds to:\")\n",
    "print(\"[\", end=' ')\n",
    "for i in input_sequences[sample]:\n",
    "    if i in reverse_word_map:\n",
    "        print(reverse_word_map[i], end=' ')\n",
    "    else:\n",
    "        print(\"__\", end=' ')\n",
    "print(\"]\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sentence like **\"the covid19 is same as \"**, we want to design a model that can predict the next word -- in the case the word **\"sars\"**.\n",
    "\n",
    "Therefore, the next code prepares our input and output to our model consequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_to_model, label = input_sequences[:,:-1],input_sequences[:,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entry  20  in 'input_sequences' is: \n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   3  12 187  34 188]\n",
      ", it corresponds to the following input to our model:\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   2   3  12 187  34]\n",
      " and the following output:  188\n"
     ]
    }
   ],
   "source": [
    "print(\"The entry \",sample,\" in 'input_sequences' is: \")\n",
    "print(input_sequences[sample])\n",
    "print(\", it corresponds to the following input to our model:\")\n",
    "print(input_to_model[sample])\n",
    "print(\" and the following output: \", label[sample])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert our label to categorical labels for being processed by our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the architecture of the model we will use:\n",
    "\n",
    "![](imgs/text_generation.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Task 1**: Implement `deep_fake_comment_model()`. You will need to carry out 5 steps:\n",
    "\n",
    "1. Create a sequencial model using the `Sequential` class\n",
    "2. Add an embedding layer to the model using the `Embedding` class of size 128\n",
    "3. Add an LSTM layer to the model using the `LSTM` class of size 128\n",
    "4. Add a Dense layer to the model using the `Dense` class with a `softmax` activation\n",
    "5. Set a `categorical_crossentropy` loss function to the model and optimize `accuracy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1\n",
    "# deep_fake_comment_model\n",
    "\n",
    "def deep_fake_comment_model():\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=total_words, output_dim=128))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "#Print details of the model.\n",
    "model = deep_fake_comment_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4030 samples\n",
      "Epoch 1/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 6.4036 - accuracy: 0.0677\n",
      "Epoch 2/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 5.8799 - accuracy: 0.0749\n",
      "Epoch 3/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 5.7335 - accuracy: 0.0950\n",
      "Epoch 4/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 5.5964 - accuracy: 0.1144\n",
      "Epoch 5/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 5.4218 - accuracy: 0.1266\n",
      "Epoch 6/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 5.2463 - accuracy: 0.1385\n",
      "Epoch 7/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 5.0678 - accuracy: 0.1588\n",
      "Epoch 8/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.8922 - accuracy: 0.1715\n",
      "Epoch 9/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.7226 - accuracy: 0.1799\n",
      "Epoch 10/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.5544 - accuracy: 0.1928\n",
      "Epoch 11/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.3925 - accuracy: 0.2045\n",
      "Epoch 12/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.2333 - accuracy: 0.2144\n",
      "Epoch 13/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 4.0695 - accuracy: 0.2333\n",
      "Epoch 14/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.9049 - accuracy: 0.2524\n",
      "Epoch 15/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.7459 - accuracy: 0.2717\n",
      "Epoch 16/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.5846 - accuracy: 0.2896\n",
      "Epoch 17/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.4241 - accuracy: 0.3072\n",
      "Epoch 18/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.2665 - accuracy: 0.3310\n",
      "Epoch 19/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 3.1084 - accuracy: 0.3551\n",
      "Epoch 20/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.9597 - accuracy: 0.3821\n",
      "Epoch 21/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.8096 - accuracy: 0.4030\n",
      "Epoch 22/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.6606 - accuracy: 0.4308\n",
      "Epoch 23/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.5191 - accuracy: 0.4628\n",
      "Epoch 24/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.3791 - accuracy: 0.4923\n",
      "Epoch 25/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.2430 - accuracy: 0.5355\n",
      "Epoch 26/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 2.1141 - accuracy: 0.5615\n",
      "Epoch 27/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 1.9898 - accuracy: 0.5975\n",
      "Epoch 28/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 1.8708 - accuracy: 0.6228\n",
      "Epoch 29/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.7541 - accuracy: 0.6583\n",
      "Epoch 30/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 1.6458 - accuracy: 0.6829\n",
      "Epoch 31/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 1.5402 - accuracy: 0.7127\n",
      "Epoch 32/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.4422 - accuracy: 0.7352\n",
      "Epoch 33/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.3510 - accuracy: 0.7600\n",
      "Epoch 34/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 1.2637 - accuracy: 0.7777\n",
      "Epoch 35/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.1844 - accuracy: 0.7963\n",
      "Epoch 36/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.1086 - accuracy: 0.8069\n",
      "Epoch 37/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 1.0421 - accuracy: 0.8221\n",
      "Epoch 38/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.9776 - accuracy: 0.8355\n",
      "Epoch 39/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.9173 - accuracy: 0.8496\n",
      "Epoch 40/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.8616 - accuracy: 0.8541\n",
      "Epoch 41/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.8110 - accuracy: 0.8682\n",
      "Epoch 42/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.7627 - accuracy: 0.8759\n",
      "Epoch 43/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.7184 - accuracy: 0.8883\n",
      "Epoch 44/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.6750 - accuracy: 0.8916\n",
      "Epoch 45/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.6397 - accuracy: 0.8968\n",
      "Epoch 46/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.6008 - accuracy: 0.9040\n",
      "Epoch 47/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.5682 - accuracy: 0.9047\n",
      "Epoch 48/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.5388 - accuracy: 0.9124\n",
      "Epoch 49/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.5112 - accuracy: 0.9159\n",
      "Epoch 50/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.4844 - accuracy: 0.9176\n",
      "Epoch 51/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.4595 - accuracy: 0.9221\n",
      "Epoch 52/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.4372 - accuracy: 0.9241\n",
      "Epoch 53/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.4163 - accuracy: 0.9305\n",
      "Epoch 54/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.3953 - accuracy: 0.9320\n",
      "Epoch 55/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.3779 - accuracy: 0.9357\n",
      "Epoch 56/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.3598 - accuracy: 0.9367\n",
      "Epoch 57/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.3439 - accuracy: 0.9392\n",
      "Epoch 58/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.3283 - accuracy: 0.9392\n",
      "Epoch 59/200\n",
      "4030/4030 [==============================] - 29s 7ms/sample - loss: 0.3135 - accuracy: 0.9437\n",
      "Epoch 60/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.3019 - accuracy: 0.9417\n",
      "Epoch 61/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.2907 - accuracy: 0.9419\n",
      "Epoch 62/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.2800 - accuracy: 0.9439\n",
      "Epoch 63/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.2703 - accuracy: 0.9442\n",
      "Epoch 64/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.2599 - accuracy: 0.9449\n",
      "Epoch 65/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.2528 - accuracy: 0.9462\n",
      "Epoch 66/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.2429 - accuracy: 0.9459\n",
      "Epoch 67/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.2354 - accuracy: 0.9471\n",
      "Epoch 68/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.2290 - accuracy: 0.9444\n",
      "Epoch 69/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.2224 - accuracy: 0.9452\n",
      "Epoch 70/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.2186 - accuracy: 0.9476\n",
      "Epoch 71/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.2106 - accuracy: 0.9479\n",
      "Epoch 72/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.2066 - accuracy: 0.9476\n",
      "Epoch 73/200\n",
      "4030/4030 [==============================] - 40s 10ms/sample - loss: 0.1996 - accuracy: 0.9469\n",
      "Epoch 74/200\n",
      "4030/4030 [==============================] - 33s 8ms/sample - loss: 0.1960 - accuracy: 0.9484\n",
      "Epoch 75/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.1922 - accuracy: 0.9479\n",
      "Epoch 76/200\n",
      "4030/4030 [==============================] - 33s 8ms/sample - loss: 0.1895 - accuracy: 0.9481\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1846 - accuracy: 0.9489\n",
      "Epoch 78/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1818 - accuracy: 0.9491\n",
      "Epoch 79/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.1782 - accuracy: 0.9474\n",
      "Epoch 80/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1740 - accuracy: 0.9486\n",
      "Epoch 81/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1729 - accuracy: 0.9474\n",
      "Epoch 82/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.1701 - accuracy: 0.9481\n",
      "Epoch 83/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1678 - accuracy: 0.9481\n",
      "Epoch 84/200\n",
      "4030/4030 [==============================] - 30s 7ms/sample - loss: 0.1724 - accuracy: 0.9476\n",
      "Epoch 85/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1775 - accuracy: 0.9459\n",
      "Epoch 86/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1727 - accuracy: 0.9469\n",
      "Epoch 87/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1614 - accuracy: 0.9471\n",
      "Epoch 88/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1582 - accuracy: 0.9486\n",
      "Epoch 89/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1566 - accuracy: 0.9489\n",
      "Epoch 90/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1544 - accuracy: 0.9486\n",
      "Epoch 91/200\n",
      "4030/4030 [==============================] - 29s 7ms/sample - loss: 0.1529 - accuracy: 0.9496\n",
      "Epoch 92/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1521 - accuracy: 0.9481\n",
      "Epoch 93/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1503 - accuracy: 0.9501\n",
      "Epoch 94/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1491 - accuracy: 0.9476\n",
      "Epoch 95/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1484 - accuracy: 0.9496\n",
      "Epoch 96/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1476 - accuracy: 0.9486\n",
      "Epoch 97/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1464 - accuracy: 0.9489\n",
      "Epoch 98/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1457 - accuracy: 0.9494\n",
      "Epoch 99/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1447 - accuracy: 0.9496\n",
      "Epoch 100/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1441 - accuracy: 0.9484\n",
      "Epoch 101/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1432 - accuracy: 0.9457\n",
      "Epoch 102/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1410 - accuracy: 0.9486\n",
      "Epoch 103/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1408 - accuracy: 0.9491\n",
      "Epoch 104/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1400 - accuracy: 0.9496\n",
      "Epoch 105/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1400 - accuracy: 0.9491\n",
      "Epoch 106/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1410 - accuracy: 0.9506\n",
      "Epoch 107/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1396 - accuracy: 0.9486\n",
      "Epoch 108/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1399 - accuracy: 0.9489\n",
      "Epoch 109/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1380 - accuracy: 0.9499\n",
      "Epoch 110/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1383 - accuracy: 0.9484\n",
      "Epoch 111/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1367 - accuracy: 0.9501\n",
      "Epoch 112/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1357 - accuracy: 0.9496\n",
      "Epoch 113/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1358 - accuracy: 0.9506\n",
      "Epoch 114/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1354 - accuracy: 0.9499\n",
      "Epoch 115/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1378 - accuracy: 0.9474\n",
      "Epoch 116/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1495 - accuracy: 0.9447\n",
      "Epoch 117/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1653 - accuracy: 0.9439\n",
      "Epoch 118/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1495 - accuracy: 0.9457\n",
      "Epoch 119/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1369 - accuracy: 0.9506\n",
      "Epoch 120/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1340 - accuracy: 0.9484\n",
      "Epoch 121/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1332 - accuracy: 0.9486\n",
      "Epoch 122/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1321 - accuracy: 0.9494\n",
      "Epoch 123/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1316 - accuracy: 0.9496\n",
      "Epoch 124/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1317 - accuracy: 0.9511\n",
      "Epoch 125/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1316 - accuracy: 0.9501\n",
      "Epoch 126/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1310 - accuracy: 0.9516\n",
      "Epoch 127/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1309 - accuracy: 0.9496\n",
      "Epoch 128/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1305 - accuracy: 0.9494\n",
      "Epoch 129/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.1307 - accuracy: 0.9489\n",
      "Epoch 130/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1317 - accuracy: 0.9491\n",
      "Epoch 131/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1308 - accuracy: 0.9496\n",
      "Epoch 132/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1298 - accuracy: 0.9499\n",
      "Epoch 133/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1302 - accuracy: 0.9491\n",
      "Epoch 134/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1292 - accuracy: 0.9481\n",
      "Epoch 135/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1292 - accuracy: 0.9486\n",
      "Epoch 136/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1294 - accuracy: 0.9514\n",
      "Epoch 137/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1296 - accuracy: 0.9496\n",
      "Epoch 138/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1290 - accuracy: 0.9486\n",
      "Epoch 139/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1282 - accuracy: 0.9504\n",
      "Epoch 140/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1284 - accuracy: 0.9496\n",
      "Epoch 141/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1281 - accuracy: 0.9489\n",
      "Epoch 142/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1281 - accuracy: 0.9506\n",
      "Epoch 143/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1278 - accuracy: 0.9486\n",
      "Epoch 144/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1283 - accuracy: 0.9494\n",
      "Epoch 145/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1481 - accuracy: 0.9467\n",
      "Epoch 146/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1553 - accuracy: 0.9437\n",
      "Epoch 147/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1379 - accuracy: 0.9484\n",
      "Epoch 148/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1353 - accuracy: 0.9496\n",
      "Epoch 149/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1314 - accuracy: 0.9489\n",
      "Epoch 150/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1299 - accuracy: 0.9491\n",
      "Epoch 151/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1292 - accuracy: 0.9474\n",
      "Epoch 152/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1282 - accuracy: 0.9526\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1275 - accuracy: 0.9496\n",
      "Epoch 154/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1276 - accuracy: 0.9486\n",
      "Epoch 155/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1275 - accuracy: 0.9484\n",
      "Epoch 156/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1268 - accuracy: 0.9504\n",
      "Epoch 157/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1270 - accuracy: 0.9484\n",
      "Epoch 158/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1273 - accuracy: 0.9499\n",
      "Epoch 159/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1272 - accuracy: 0.9494\n",
      "Epoch 160/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1266 - accuracy: 0.9501\n",
      "Epoch 161/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1266 - accuracy: 0.9509\n",
      "Epoch 162/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1266 - accuracy: 0.9496\n",
      "Epoch 163/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1273 - accuracy: 0.9484\n",
      "Epoch 164/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1272 - accuracy: 0.9509\n",
      "Epoch 165/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1265 - accuracy: 0.9504\n",
      "Epoch 166/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1272 - accuracy: 0.9516\n",
      "Epoch 167/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1270 - accuracy: 0.9506\n",
      "Epoch 168/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1270 - accuracy: 0.9501\n",
      "Epoch 169/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1266 - accuracy: 0.9491\n",
      "Epoch 170/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1265 - accuracy: 0.9499\n",
      "Epoch 171/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1268 - accuracy: 0.9504\n",
      "Epoch 172/200\n",
      "4030/4030 [==============================] - 28s 7ms/sample - loss: 0.1263 - accuracy: 0.9481\n",
      "Epoch 173/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1266 - accuracy: 0.9501\n",
      "Epoch 174/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1266 - accuracy: 0.9506\n",
      "Epoch 175/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1266 - accuracy: 0.9501\n",
      "Epoch 176/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1262 - accuracy: 0.9516\n",
      "Epoch 177/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1268 - accuracy: 0.9501\n",
      "Epoch 178/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1260 - accuracy: 0.9501\n",
      "Epoch 179/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1276 - accuracy: 0.9501\n",
      "Epoch 180/200\n",
      "4030/4030 [==============================] - 23s 6ms/sample - loss: 0.1296 - accuracy: 0.9504\n",
      "Epoch 181/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1516 - accuracy: 0.9444\n",
      "Epoch 182/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1487 - accuracy: 0.9437\n",
      "Epoch 183/200\n",
      "4030/4030 [==============================] - 78s 19ms/sample - loss: 0.1329 - accuracy: 0.9506\n",
      "Epoch 184/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1280 - accuracy: 0.9484\n",
      "Epoch 185/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1293 - accuracy: 0.9479\n",
      "Epoch 186/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1279 - accuracy: 0.9486\n",
      "Epoch 187/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1270 - accuracy: 0.9511\n",
      "Epoch 188/200\n",
      "4030/4030 [==============================] - 27s 7ms/sample - loss: 0.1262 - accuracy: 0.9501\n",
      "Epoch 189/200\n",
      "4030/4030 [==============================] - 26s 7ms/sample - loss: 0.1262 - accuracy: 0.9489\n",
      "Epoch 190/200\n",
      "4030/4030 [==============================] - 26s 6ms/sample - loss: 0.1259 - accuracy: 0.9496\n",
      "Epoch 191/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1260 - accuracy: 0.9476\n",
      "Epoch 192/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1259 - accuracy: 0.9499\n",
      "Epoch 193/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1258 - accuracy: 0.9506\n",
      "Epoch 194/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1254 - accuracy: 0.9514\n",
      "Epoch 195/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1256 - accuracy: 0.9494\n",
      "Epoch 196/200\n",
      "4030/4030 [==============================] - 25s 6ms/sample - loss: 0.1252 - accuracy: 0.9514\n",
      "Epoch 197/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1259 - accuracy: 0.9489\n",
      "Epoch 198/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1251 - accuracy: 0.9511\n",
      "Epoch 199/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1259 - accuracy: 0.9479\n",
      "Epoch 200/200\n",
      "4030/4030 [==============================] - 24s 6ms/sample - loss: 0.1251 - accuracy: 0.9516\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_to_model, label, epochs=200, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot details of our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.title('Training accuracy')\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating fake comments\n",
    "\n",
    "To generate fake tweets, we use the below architecture:\n",
    "\n",
    "![](imgs/text_gen.png)\n",
    "\n",
    "The idea is to give one or more starting token(s) to our model, and generate the next tokens until we generate `.`.\n",
    "\n",
    "At each step, we select the token with the highest probability as our next token and generate the next one similartly using `model.predict_classes()`. \n",
    "\n",
    "**Note:** The model takes as input the activation `a` from the previous state of the LSTM and the token chosen, forward propagate by one step, and get a new output activation `a`. The new activation `a` can then be used to generate the output, using the `dense` layer with `softmax` activation as before. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Implement `generate()`. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 2\n",
    "# Implement the generate() function\n",
    "\n",
    "def generate(seed_text):\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    #First, split string into input array of tokens\n",
    "    tokens = np.asarray(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "    \n",
    "    #We need to cut off the first tokens later, so record length now\n",
    "    original_count = len(tokens)\n",
    "    \n",
    "    #Loop until max seq len has been reached, we may exit sooner\n",
    "    for loop in range(max_sequence_len):\n",
    "        \n",
    "        #With our tokens array, we want to pad\n",
    "        padded = pad_sequences([tokens], maxlen=max_sequence_len, padding='pre')\n",
    "    \n",
    "        #Feed into trained model to get prediction for next word\n",
    "        predict = model.predict_classes(padded,batch_size=32)\n",
    "        \n",
    "        #Append the next word to the tokens list (without the padding)\n",
    "        tokens = np.append(tokens, predict[0])\n",
    "        \n",
    "        #If the predicted next word is EOS ('.'), we need to generate the string and return it\n",
    "        if reverse_word_map[predict[0]] == '.' or loop == max_sequence_len:\n",
    "            #Build our coherant string, starting with the original string\n",
    "            return_string = seed_text\n",
    "            \n",
    "            #strip the tokens from the first part of token array, because we added the string directly\n",
    "            tokens = tokens[original_count:]\n",
    "                \n",
    "            for i in range(len(tokens[:])):\n",
    "                #If next string is a fullstop, add it and return string\n",
    "                if reverse_word_map[tokens[i]] == '.':\n",
    "                    return_string += '.'\n",
    "                    return(return_string)\n",
    "                elif reverse_word_map[tokens[i]] == ',':\n",
    "                    #no space, add comma\n",
    "                    return_string += ','\n",
    "                else:\n",
    "                    #add a space then add the string\n",
    "                    return_string += ' '\n",
    "                    return_string += reverse_word_map[tokens[i]]\n",
    "                    \n",
    "            #if somehow we haven't seen a '.', return the string we have anyway\n",
    "            return(return_string)\n",
    "\n",
    "\n",
    "    ### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's test it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID19 virus cannot be transmitted in areas with hot and humid climates.\n",
      "COVID19 is the deadliest virus known to humans.\n",
      "The usa is the covid19 was caused by an accidental leak from wuhan virus research institute.\n",
      "The new virus was engineered by scientists in a lab.\n"
     ]
    }
   ],
   "source": [
    "print(generate(\"COVID19 virus\"))\n",
    "print(generate(\"COVID19 is the\"))\n",
    "print(generate(\"The usa is\"))\n",
    "print(generate(\"The new virus\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's test it in an interactive mode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your tweet, the algorithm machine will complete it. Your input is: Covid19 is not\n",
      "Covid19 is not covid 1, folks. "
     ]
    }
   ],
   "source": [
    "usr_input = input(\"Write the beginning of your tweet, the algorithm machine will complete it. Your input is: \")\n",
    "for w in generate(usr_input).split():    \n",
    "    print(w, end =\" \")\n",
    "    time.sleep(0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating text by sampling\n",
    "\n",
    "The previous part is generating text by choosing the token with the highest probability. Now, we sill generate text by sampling as shown in the architecture below:\n",
    "\n",
    "![](imgs/text_gen_sample.png)\n",
    "\n",
    "\n",
    "**TASK 3:** Implement the `generate_sample()` function. To sample a token from the output at each timestep, you need to use the following two functions:\n",
    "- `model.predict_proba()`: To get probabilities from the output layer.\n",
    "- `np.random.choice()`: To sample from the token list using the probaility array of each token.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 3\n",
    "# Implement the generate_sample() function\n",
    "def generate_sample(seed_text):\n",
    "   ### START CODE HERE ### \n",
    "   \n",
    "    #First, split string into input array of tokens\n",
    "    tokens = np.asarray(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "    \n",
    "    #We need to cut off the first tokens later, so record length now\n",
    "    original_count = len(tokens)\n",
    "    \n",
    "    #Loop until max seq len has been reached, we may exit sooner\n",
    "    for loop in range(max_sequence_len):\n",
    "        \n",
    "        #With our tokens array, we want to pad\n",
    "        padded = pad_sequences([tokens], maxlen=max_sequence_len, padding='pre')\n",
    "    \n",
    "        #Feed into trained model to get probability of prediction\n",
    "        predict_Prob = model.predict_proba(padded,batch_size=32)\n",
    "\n",
    "        #Select random choice using array of prediction probabilities\n",
    "        predict = np.random.choice(total_words,p=predict_Prob[0])\n",
    "\n",
    "        \n",
    "        #Append the next word to the tokens list (without the padding)\n",
    "        tokens = np.append(tokens, predict)\n",
    "        \n",
    "        #If the predicted next word is EOS ('.'), we need to generate the string and return it\n",
    "        if reverse_word_map[predict] == '.' or loop == max_sequence_len:\n",
    "            #Build our coherant string, starting with the original string\n",
    "            return_string = seed_text\n",
    "            \n",
    "            #strip the tokens from the first part of token array, because we added the string directly\n",
    "            tokens = tokens[original_count:]\n",
    "                \n",
    "            for i in range(len(tokens[:])):\n",
    "                #If next string is a fullstop, add it and return string\n",
    "                if reverse_word_map[tokens[i]] == '.':\n",
    "                    return_string += '.'\n",
    "                    return(return_string)\n",
    "                elif reverse_word_map[tokens[i]] == ',':\n",
    "                    #no space, add comma\n",
    "                    return_string += ','\n",
    "                else:\n",
    "                    #add a space then add the string\n",
    "                    return_string += ' '\n",
    "                    return_string += reverse_word_map[tokens[i]]\n",
    "                    \n",
    "            #if somehow we haven't seen a '.', return the string we have anyway\n",
    "            return(return_string)\n",
    "\n",
    "\n",
    "\n",
    "    ### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's test it in an interactive mode:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write the beginning of your tweet, the algorithm machine will complete it. Your input is: covid19 is the\n",
      "covid19 is the deadliest virus known to humans. "
     ]
    }
   ],
   "source": [
    "usr_input = input(\"Write the beginning of your tweet, the algorithm machine will complete it. Your input is: \")\n",
    "for w in generate_sample(usr_input).split():    \n",
    "    print(w, end =\" \")\n",
    "    time.sleep(0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate your own text \n",
    "\n",
    "Below, use you own data to generate content for a different application:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a quiz dataset with random set of questions (https://www.kaggle.com/theriley106/hq-trivia-question-database)\n",
    "Obviously, as the questions will be somewhat non-sensical, there are no answers.  All non-question fields have been stripped.\n",
    "\n",
    "Questions generally start with \"who\" \"what\" \"where\" etc, and end with '?'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\"#$%&()*+-/:;<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "data = open('questions.txt').read().replace(\".\", \" . \").replace(\",\", \" , \").replace(\"?\", \" ? \").replace(\"!\", \" ! \").replace(\"\\'\", \"\").replace(\"\\\"\", \"\").replace(\"\",\"\").replace(\"\",\"\")\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        \n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "input_to_model, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19329 samples\n",
      "Epoch 1/50\n",
      "19329/19329 [==============================] - 69s 4ms/sample - loss: 6.4425 - accuracy: 0.1181\n",
      "Epoch 2/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 5.5725 - accuracy: 0.2062\n",
      "Epoch 3/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 5.0495 - accuracy: 0.2554\n",
      "Epoch 4/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 4.6620 - accuracy: 0.2841\n",
      "Epoch 5/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 4.3418 - accuracy: 0.3058\n",
      "Epoch 6/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 4.0527 - accuracy: 0.3214\n",
      "Epoch 7/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 3.7812 - accuracy: 0.3409\n",
      "Epoch 8/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 3.5245 - accuracy: 0.3601\n",
      "Epoch 9/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 3.2773 - accuracy: 0.3814\n",
      "Epoch 10/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 3.0404 - accuracy: 0.4105\n",
      "Epoch 11/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 2.8045 - accuracy: 0.4464\n",
      "Epoch 12/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 2.5828 - accuracy: 0.4912\n",
      "Epoch 13/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 2.3688 - accuracy: 0.5305\n",
      "Epoch 14/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 2.1700 - accuracy: 0.5685\n",
      "Epoch 15/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 1.9884 - accuracy: 0.6024\n",
      "Epoch 16/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 1.8263 - accuracy: 0.6371\n",
      "Epoch 17/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 1.6805 - accuracy: 0.6656\n",
      "Epoch 18/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 1.5514 - accuracy: 0.6922\n",
      "Epoch 19/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 1.4351 - accuracy: 0.7152\n",
      "Epoch 20/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 1.3322 - accuracy: 0.7371\n",
      "Epoch 21/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 1.2414 - accuracy: 0.7562\n",
      "Epoch 22/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 1.1559 - accuracy: 0.7735\n",
      "Epoch 23/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 1.0782 - accuracy: 0.7929\n",
      "Epoch 24/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 1.0110 - accuracy: 0.8075\n",
      "Epoch 25/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.9515 - accuracy: 0.8177\n",
      "Epoch 26/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.8919 - accuracy: 0.8303\n",
      "Epoch 27/50\n",
      "19329/19329 [==============================] - 70s 4ms/sample - loss: 0.8421 - accuracy: 0.8411\n",
      "Epoch 28/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 0.7965 - accuracy: 0.8489\n",
      "Epoch 29/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 0.7569 - accuracy: 0.8574\n",
      "Epoch 30/50\n",
      "19329/19329 [==============================] - 65s 3ms/sample - loss: 0.7207 - accuracy: 0.8629\n",
      "Epoch 31/50\n",
      "19329/19329 [==============================] - 66s 3ms/sample - loss: 0.6900 - accuracy: 0.8666\n",
      "Epoch 32/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.6620 - accuracy: 0.8720\n",
      "Epoch 33/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.6342 - accuracy: 0.8779\n",
      "Epoch 34/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.6135 - accuracy: 0.8799\n",
      "Epoch 35/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5914 - accuracy: 0.8847\n",
      "Epoch 36/50\n",
      "19329/19329 [==============================] - 69s 4ms/sample - loss: 0.5746 - accuracy: 0.8862\n",
      "Epoch 37/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5630 - accuracy: 0.8865\n",
      "Epoch 38/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5473 - accuracy: 0.8896\n",
      "Epoch 39/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5313 - accuracy: 0.8912\n",
      "Epoch 40/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5222 - accuracy: 0.8928\n",
      "Epoch 41/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5119 - accuracy: 0.8930\n",
      "Epoch 42/50\n",
      "19329/19329 [==============================] - 68s 3ms/sample - loss: 0.5079 - accuracy: 0.8935\n",
      "Epoch 43/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.5007 - accuracy: 0.8941\n",
      "Epoch 44/50\n",
      "19329/19329 [==============================] - 67s 3ms/sample - loss: 0.4911 - accuracy: 0.8956\n",
      "Epoch 45/50\n",
      "19329/19329 [==============================] - 68s 4ms/sample - loss: 0.4847 - accuracy: 0.8963\n",
      "Epoch 46/50\n",
      "19329/19329 [==============================] - 68s 3ms/sample - loss: 0.4783 - accuracy: 0.8956\n",
      "Epoch 47/50\n",
      "19329/19329 [==============================] - 68s 3ms/sample - loss: 0.4737 - accuracy: 0.8967\n",
      "Epoch 48/50\n",
      "19329/19329 [==============================] - 68s 4ms/sample - loss: 0.4715 - accuracy: 0.8966\n",
      "Epoch 49/50\n",
      "19329/19329 [==============================] - 68s 4ms/sample - loss: 0.4667 - accuracy: 0.8963\n",
      "Epoch 50/50\n",
      "19329/19329 [==============================] - 68s 4ms/sample - loss: 0.4625 - accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "def deep_fake_comment_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=total_words, output_dim=128))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(total_words, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model) \n",
    "    \n",
    "#Print details of the model.\n",
    "model_two = deep_fake_comment_model()\n",
    "\n",
    "history_two = model_two.fit(input_to_model, label, epochs=50, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the only u. s. state home to two ivy league schools?\n",
      "Who was the first u. s. president to enjoy indoor plumbing at the white house?\n",
      "How did senator strom thurmond prepare for the longest ever u. s. congressional filibuster?\n",
      "When did flight for what, if obtained, which of these is actually from a fuzzless peach?\n",
      "Where did the budget retailer poundland open its first store in 1990?\n",
      "What is the largest planet in our solar system?\n",
      "What shape is the scientific term for a music in france?\n",
      "What color is a home to the most wonderful movie that played if an aculeus?\n"
     ]
    }
   ],
   "source": [
    "def generate_question(seed_text):\n",
    "   \n",
    "    #First, split string into input array of tokens\n",
    "    tokens = np.asarray(tokenizer.texts_to_sequences([seed_text])[0])\n",
    "    \n",
    "    #We need to cut off the first tokens later, so record length now\n",
    "    original_count = len(tokens)\n",
    "    \n",
    "    #Loop until max seq len has been reached, we may exit sooner\n",
    "    for loop in range(max_sequence_len):\n",
    "        \n",
    "        #With our tokens array, we want to pad\n",
    "        padded = pad_sequences([tokens], maxlen=max_sequence_len, padding='pre')\n",
    "    \n",
    "        #Feed into trained model to get probability of prediction\n",
    "        predict_Prob = model_two.predict_proba(padded,batch_size=32)\n",
    "\n",
    "        #Select random choice using array of prediction probabilities\n",
    "        predict = np.random.choice(total_words,p=predict_Prob[0])\n",
    "\n",
    "        \n",
    "        #Append the next word to the tokens list (without the padding)\n",
    "        tokens = np.append(tokens, predict)\n",
    "        \n",
    "        #Change this so that questions end with a '?', rather than '.'\n",
    "        if reverse_word_map[predict] == '?' or loop == max_sequence_len:\n",
    "            #Build our coherant string, starting with the original string\n",
    "            return_string = seed_text\n",
    "            \n",
    "            #strip the tokens from the first part of token array, because we added the string directly\n",
    "            tokens = tokens[original_count:]\n",
    "                \n",
    "            for i in range(len(tokens[:])):\n",
    "                #If next string is a fullstop, add it and return string\n",
    "                if reverse_word_map[tokens[i]] == '?':\n",
    "                    return_string += '?'\n",
    "                    return(return_string)\n",
    "                elif reverse_word_map[tokens[i]] == ',':\n",
    "                    #no space, add comma\n",
    "                    return_string += ','\n",
    "                elif reverse_word_map[tokens[i]] == '.':\n",
    "                    #no space, add comma\n",
    "                    return_string += '.'\n",
    "                else:\n",
    "                    #add a space then add the string\n",
    "                    return_string += ' '\n",
    "                    return_string += reverse_word_map[tokens[i]]\n",
    "                    \n",
    "            #if somehow we haven't seen a '?', return the string we have anyway\n",
    "            return(return_string)\n",
    "        \n",
    "print(generate_question(\"What is\"))\n",
    "print(generate_question(\"Who was\"))\n",
    "print(generate_question(\"How did\"))\n",
    "print(generate_question(\"When did\"))\n",
    "print(generate_question(\"Where did\"))\n",
    "print(generate_question(\"What is the largest\"))\n",
    "print(generate_question(\"What shape is\"))\n",
    "print(generate_question(\"What color is\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "You've come to the end of this assignment, and have seen how to build a deep learning architecture that generate fake tweets/comments. \n",
    "\n",
    "Congratulations on finishing this notebook! \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Shakespeare_generatoripynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
